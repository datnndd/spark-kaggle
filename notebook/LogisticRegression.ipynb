{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/tmp/spark-events', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0540223b-b9f1-498f-8386-a00c7df30ef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/26 23:05:36 WARN Utils: Your hostname, datnd-Nitro-AN515-57, resolves to a loopback address: 127.0.1.1; using 192.168.101.128 instead (on interface wlp0s20f3)\n",
      "25/12/26 23:05:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/26 23:05:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Stop any existing context\n",
    "try:\n",
    "    SparkContext.getOrCreate().stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Now create a new session\n",
    "spark = SparkSession.builder.appName(\"LogisticRegression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8cf651-c01e-4ec8-a161-e1de5860d0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/26 23:05:48 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7883241261187369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8029936399661157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall: 0.7883241261187368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.7922538670149973\n",
      "Test Accuracy: 0.7879562892350617\n",
      "Test Precision: 0.8027204909542864\n",
      "Test Recall: 0.7879562892350616\n",
      "Test F1: 0.7919204364899317\n"
     ]
    }
   ],
   "source": [
    "df_train = spark.read.csv(\"/home/datnd/Projects/spark-kaggle/data/train.csv\", header=True, inferSchema=True)\n",
    "\n",
    "target_col = \"accident_risk_level\"\n",
    "\n",
    "def add_features(df):\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"is_night\", (F.col(\"lighting\") == \"night\").cast(\"int\"))\n",
    "        .withColumn(\"bad_weather\", (F.col(\"weather\").isin(\"foggy\", \"rainy\")).cast(\"int\"))\n",
    "        .withColumn(\"high_curvature\", (F.col(\"curvature\") >= 0.5).cast(\"int\"))\n",
    "        .withColumn(\"high_speed\", (F.col(\"speed_limit\") >= 60).cast(\"int\"))\n",
    "        .withColumn(\"night_high_curvature\", (F.col(\"is_night\") * F.col(\"high_curvature\")).cast(\"int\"))\n",
    "        .withColumn(\"night_high_speed\", (F.col(\"is_night\") * F.col(\"high_speed\")).cast(\"int\"))\n",
    "        .withColumn(\"high_curvature_bad_weather\", (F.col(\"high_curvature\") * F.col(\"bad_weather\")).cast(\"int\"))\n",
    "        .withColumn(\"curvature_x_night\", F.col(\"curvature\") * F.col(\"is_night\"))\n",
    "        .withColumn(\"speed_x_night\", F.col(\"speed_limit\") * F.col(\"is_night\"))\n",
    "        .withColumn(\"road_signs_present_i\", F.col(\"road_signs_present\").cast(\"int\"))\n",
    "        .withColumn(\"public_road_i\", F.col(\"public_road\").cast(\"int\"))\n",
    "        .withColumn(\"holiday_i\", F.col(\"holiday\").cast(\"int\"))\n",
    "        .withColumn(\"school_season_i\", F.col(\"school_season\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "# split\n",
    "train_df, test_df = df_train.randomSplit([0.8, 0.2], seed=42)\n",
    "train_fe = add_features(train_df)\n",
    "test_fe  = add_features(test_df)\n",
    "\n",
    "categorical_cols = [\"road_type\", \"lighting\", \"weather\", \"time_of_day\"]\n",
    "\n",
    "numeric_cols = [\"num_lanes\", \"curvature\", \"speed_limit\", \"num_reported_accidents\"]\n",
    "interaction_numeric_cols = [\"curvature_x_night\", \"speed_x_night\"]\n",
    "numeric_to_scale = numeric_cols + interaction_numeric_cols\n",
    "\n",
    "boolean_features = [\n",
    "    \"is_night\", \"bad_weather\", \"high_curvature\", \"high_speed\",\n",
    "    \"night_high_curvature\", \"night_high_speed\", \"high_curvature_bad_weather\",\n",
    "    \"road_signs_present_i\", \"public_road_i\", \"holiday_i\", \"school_season_i\"\n",
    "]\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=target_col, outputCol=\"label\", handleInvalid=\"keep\")\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\", dropLast=True) for c in categorical_cols]\n",
    "\n",
    "num_assembler = VectorAssembler(inputCols=numeric_to_scale, outputCol=\"num_raw\", handleInvalid=\"keep\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"num_raw\", outputCol=\"num_scaled\", withMean=False, withStd=True)\n",
    "\n",
    "bool_assembler = VectorAssembler(inputCols=boolean_features, outputCol=\"bool_features\", handleInvalid=\"keep\")\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=[\"num_scaled\", \"bool_features\"] + [f\"{c}_ohe\" for c in categorical_cols],\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    family=\"multinomial\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01,\n",
    "    elasticNetParam=0.0\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    *indexers, *encoders,\n",
    "    num_assembler, scaler,\n",
    "    bool_assembler,\n",
    "    final_assembler,\n",
    "    lr\n",
    "])\n",
    "\n",
    "model = pipeline.fit(train_fe)\n",
    "train = model.transform(train_fe)\n",
    "pred = model.transform(test_fe)\n",
    "\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "\n",
    "print(\"Train Accuracy:\", evaluator_acc.evaluate(train))\n",
    "print(\"Train Precision:\", evaluator_precision.evaluate(train))\n",
    "print(\"Train Recall:\", evaluator_recall.evaluate(train))\n",
    "print(\"Train F1:\", evaluator_f1.evaluate(train))\n",
    "print(\"Test Accuracy:\", evaluator_acc.evaluate(pred))\n",
    "print(\"Test Precision:\", evaluator_precision.evaluate(pred))\n",
    "print(\"Test Recall:\", evaluator_recall.evaluate(pred))\n",
    "print(\"Test F1:\", evaluator_f1.evaluate(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Feature Importance Extraction =====\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Extract the LogisticRegressionModel from the Pipeline\n",
    "lr_model = model.stages[-1]\n",
    "print(\"Coefficients shape:\", lr_model.coefficientMatrix.toArray().shape)\n",
    "\n",
    "# 2) Reconstruct feature names\n",
    "# Numeric + Interaction features\n",
    "num_features = numeric_to_scale\n",
    "\n",
    "# Boolean features\n",
    "bool_feats = boolean_features\n",
    "\n",
    "# OHE features\n",
    "# We iterate through the StringIndexer models to get labels.\n",
    "# pipeline.stages[1:5] are the StringIndexers (4 categorical cols)\n",
    "ohe_features = []\n",
    "\n",
    "# The StringIndexers are at indices 1 to 4 (inclusive) in the pipeline stages definition:\n",
    "# stages=[label_indexer (0), *indexers (1..4), *encoders (5..8), ...]\n",
    "# Let's grab them dynamically to be safe.\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "\n",
    "# Filter for StringIndexerModels that were part of our categorical input\n",
    "si_models = [stage for stage in model.stages if isinstance(stage, StringIndexerModel) and stage.getOutputCol() in [f\"{c}_idx\" for c in categorical_cols]]\n",
    "\n",
    "for si in si_models:\n",
    "    c_name = si.getInputCol()\n",
    "    labels = si.labels\n",
    "    # With handleInvalid=\"keep\", there is an extra hidden bucket for invalid/unknown values at index = len(labels).\n",
    "    # OneHotEncoder(dropLast=True) drops the last category.\n",
    "    # Since the indices are [0, 1, ..., len(labels)-1, len(labels)], \n",
    "    # the last one (the 'invalid' bucket) is dropped.\n",
    "    # Thus, ALL original labels are kept as features.\n",
    "    ohe_features += [f\"{c_name}={lbl}\" for lbl in labels]\n",
    "\n",
    "feature_names = num_features + bool_feats + ohe_features\n",
    "\n",
    "print(f\"Total features constructed: {len(feature_names)}\")\n",
    "print(f\"Model features: {lr_model.numFeatures}\")\n",
    "\n",
    "assert len(feature_names) == lr_model.numFeatures, \"Feature count mismatch!\"\n",
    "\n",
    "# 3) Create a DataFrame of Feature Importances\n",
    "# For multinomial logistic regression, coefficientMatrix is (numClasses, numFeatures)\n",
    "# We can look at the coefficients for a specific class or aggregate them.\n",
    "# Here, let's look at the max absolute coefficient across classes for each feature.\n",
    "coefs = lr_model.coefficientMatrix.toArray()\n",
    "\n",
    "# If binary, it might be (1, numFeatures). If multinomial with K classes, (K, numFeatures).\n",
    "# Let's take the mean absolute value across classes to see general importance, \n",
    "# or if it's binary, just take the absolute value.\n",
    "import numpy as np\n",
    "if coefs.shape[0] == 1:\n",
    "    feat_imp = np.abs(coefs[0])\n",
    "else:\n",
    "    # For each feature, take max absolute impact across all classes\n",
    "    feat_imp = np.max(np.abs(coefs), axis=0)\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": feat_imp\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(df_importance.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LinearRegression",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}